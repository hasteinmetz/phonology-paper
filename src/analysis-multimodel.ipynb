{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parameters & Other Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = './trainingdata_stepwise_turkish_3_articulators.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trainingdata_stepwise_turkish_3_articulators.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from dev import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data_stepwise = Dataset(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the articulators to be used by different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounding = [\"la_output\", \"tb_output\"]\n",
    "round_and_front = [\"la_output\", \"tb_output\", \"tc_output\"]\n",
    "front = [\"tb_output\", \"tc_output\"]\n",
    "analyses = [rounding, round_and_front, front]\n",
    "\n",
    "def get_analysis_name(ls: list) -> str:\n",
    "    if ls == rounding:\n",
    "        return 'rounding'\n",
    "    if ls == round_and_front:\n",
    "        return 'round_and_front'\n",
    "    if ls == front:\n",
    "        return 'fronting'\n",
    "\n",
    "# load dataframe\n",
    "data = pd.read_csv(dataset_file, sep='\\t')\n",
    "data = data[data['syllables']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create several models for each analysis and construct a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:38<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:38<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K2/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:40<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K3/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K4/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:42<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K5/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:42<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K6/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:38<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K7/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K8/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:48<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K9/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K10/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K11/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K12/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K13/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K14/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K15/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K16/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K17/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K18/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K19/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K20/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K21/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K22/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K23/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K24/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K25/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K26/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K27/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K28/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K29/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K30/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K31/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K32/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K33/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K34/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K35/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K36/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K37/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:28<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K38/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K39/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K40/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K41/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K42/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:41<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K43/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K44/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K45/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K46/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K47/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K48/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K49/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:39<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K50/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:52<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K51/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:56<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K52/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:59<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K53/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K54/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K55/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:39<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K56/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K57/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K58/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K59/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:42<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K60/60\n",
      "             0         1         2         3         4         5         6  \\\n",
      "0     0.877493  0.891837  0.891027  0.837420  0.134618  0.484158  0.308495   \n",
      "1     0.940751  0.972527  0.976617  0.866025  0.120465  0.509531  0.234733   \n",
      "2     0.940558  0.957797  0.959046  0.919910  0.181786  0.547717  0.326072   \n",
      "3     0.523138  0.526685  0.527616  0.500620  0.306883  0.288392  0.228648   \n",
      "4     0.545067  0.561122  0.564030  0.545583  0.358564  0.297703  0.257977   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2875  0.491988  0.091367  0.059237  0.053706  0.032351  0.015354  0.014646   \n",
      "2876  0.482587  0.101485  0.073986  0.065135  0.037305  0.011806  0.016383   \n",
      "2877  0.345552  0.076055  0.048850  0.041997  0.036490  0.033191  0.031915   \n",
      "2878  0.341192  0.036247  0.021226  0.019891  0.020082  0.021487  0.018615   \n",
      "2879  0.444391  0.093248  0.070856  0.061836  0.034950  0.010113  0.016762   \n",
      "\n",
      "             7         8         9 underlying consonant V2 V1     group  model  \n",
      "0     0.016162  0.250247  0.787040       ib-H         b  H  i  rounding      1  \n",
      "1     0.014102  0.175519  0.775287       ab-H         b  H  a  rounding      1  \n",
      "2     0.021071  0.252972  0.830559       eb-H         b  H  e  rounding      1  \n",
      "3     0.089059  0.342843  0.465827       ob-H         b  H  o  rounding      1  \n",
      "4     0.089610  0.341550  0.473505       ub-H         b  H  u  rounding      1  \n",
      "...        ...       ...       ...        ...       ... .. ..       ...    ...  \n",
      "2875  0.030760  0.031159  0.165336       od-L         d  L  o  fronting     60  \n",
      "2876  0.085919  0.045626  0.161891       ud-L         d  L  u  fronting     60  \n",
      "2877  0.038442  0.042196  0.038369       yd-L         d  L  y  fronting     60  \n",
      "2878  0.016403  0.019349  0.021505       ød-L         d  L  ø  fronting     60  \n",
      "2879  0.085067  0.045280  0.170912       ɯd-L         d  L  ɯ  fronting     60  \n",
      "\n",
      "[2880 rows x 16 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define functions to be used when building the dataframe\n",
    "\n",
    "# helper function to get decoder outputs\n",
    "def get_decoder(input: torch.Tensor, target: torch.Tensor, model) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        _, attn_map_seq = model(input, target)\n",
    "    return attn_map_seq.numpy()[:,0] # attention paid to the first letter\n",
    "\n",
    "# helper functions to get correct inputs\n",
    "def get_trial(training_data, word, model):\n",
    "    trial = training_data.make_trial(word)\n",
    "    return trial[0], torch.cat((trial[1], trial[2]), axis=1), model\n",
    "\n",
    "# get the decoder outputs for each word\n",
    "get_out = lambda x, y, model : pd.DataFrame(get_decoder(*get_trial(x, y, model)))\n",
    "\n",
    "# iterate through each analysis\n",
    "df_all = None\n",
    "for k, analysis in enumerate(analyses):\n",
    "    # iterate over 20 different models\n",
    "    for j in range(20):\n",
    "        # train a new model\n",
    "        model = Seq2Seq(training_data=data_stepwise, articulators=analysis)\n",
    "        model.train_model(training_data=data_stepwise, n_epochs=200)\n",
    "        # model.save()\n",
    "\n",
    "        # get the attention values from the model\n",
    "        df = get_out(data_stepwise, data['underlying'].values[0], model).T\n",
    "        for i in range(1, data['underlying'].shape[0]):\n",
    "            df = pd.concat(\n",
    "                (df, get_out(data_stepwise, data['underlying'].values[i], model).T),\n",
    "                axis=0\n",
    "            )\n",
    "\n",
    "        # reset the indexes\n",
    "        df = df.reset_index().drop('index', axis=1)\n",
    "\n",
    "        # add columns\n",
    "        for c in ['underlying', 'consonant', 'vowel']:\n",
    "            col = data[c]\n",
    "            col = col.reset_index().drop('index', axis=1)\n",
    "            df[c] = col\n",
    "\n",
    "        df = df.rename({'vowel': \"V2\"}, axis=1)\n",
    "        df = df.assign(\n",
    "            V1 = lambda d: d['underlying'].astype(str).str[0]\n",
    "        )\n",
    "\n",
    "        df = df.assign(\n",
    "            group = get_analysis_name(analysis)\n",
    "        )\n",
    "\n",
    "        df = df.assign(\n",
    "            model = (j+1) + (k * 20)\n",
    "        )\n",
    "    \n",
    "        if isinstance(df_all, pd.DataFrame):\n",
    "            df_all = pd.concat((df_all, df), axis=0)\n",
    "        else:\n",
    "            df_all = df\n",
    "\n",
    "        print(end='\\x1b[2K')\n",
    "        print(f\"{(j+1) + (k * 20)}/{20 * len(analyses)}\")\n",
    "\n",
    "df_all = df_all.reset_index().drop('index', axis=1)\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6  \\\n",
      "0     0.877493  0.891837  0.891027  0.837420  0.134618  0.484158  0.308495   \n",
      "1     0.940751  0.972527  0.976617  0.866025  0.120465  0.509531  0.234733   \n",
      "2     0.940558  0.957797  0.959046  0.919910  0.181786  0.547717  0.326072   \n",
      "3     0.523138  0.526685  0.527616  0.500620  0.306883  0.288392  0.228648   \n",
      "4     0.545067  0.561122  0.564030  0.545583  0.358564  0.297703  0.257977   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2875  0.491988  0.091367  0.059237  0.053706  0.032351  0.015354  0.014646   \n",
      "2876  0.482587  0.101485  0.073986  0.065135  0.037305  0.011806  0.016383   \n",
      "2877  0.345552  0.076055  0.048850  0.041997  0.036490  0.033191  0.031915   \n",
      "2878  0.341192  0.036247  0.021226  0.019891  0.020082  0.021487  0.018615   \n",
      "2879  0.444391  0.093248  0.070856  0.061836  0.034950  0.010113  0.016762   \n",
      "\n",
      "             7         8         9 underlying consonant V2 V1     group  \\\n",
      "0     0.016162  0.250247  0.787040       ib-H         b  H  i  rounding   \n",
      "1     0.014102  0.175519  0.775287       ab-H         b  H  a  rounding   \n",
      "2     0.021071  0.252972  0.830559       eb-H         b  H  e  rounding   \n",
      "3     0.089059  0.342843  0.465827       ob-H         b  H  o  rounding   \n",
      "4     0.089610  0.341550  0.473505       ub-H         b  H  u  rounding   \n",
      "...        ...       ...       ...        ...       ... .. ..       ...   \n",
      "2875  0.030760  0.031159  0.165336       od-L         d  L  o  fronting   \n",
      "2876  0.085919  0.045626  0.161891       ud-L         d  L  u  fronting   \n",
      "2877  0.038442  0.042196  0.038369       yd-L         d  L  y  fronting   \n",
      "2878  0.016403  0.019349  0.021505       ød-L         d  L  ø  fronting   \n",
      "2879  0.085067  0.045280  0.170912       ɯd-L         d  L  ɯ  fronting   \n",
      "\n",
      "      model  rounded  fronted  high  \n",
      "0         1        0        1     1  \n",
      "1         1        0        0     0  \n",
      "2         1        0        1     0  \n",
      "3         1        1        0     1  \n",
      "4         1        1        0     1  \n",
      "...     ...      ...      ...   ...  \n",
      "2875     60        1        0     1  \n",
      "2876     60        1        0     1  \n",
      "2877     60        1        1     1  \n",
      "2878     60        1        1     1  \n",
      "2879     60        0        0     1  \n",
      "\n",
      "[2880 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# create additional categorical values\n",
    "df_a = df_all.assign(\n",
    "    rounded = lambda d: d[\"V1\"].apply(lambda y: 1 if y in [\"ø\", \"u\", \"y\", \"o\"] else 0)\n",
    ")\n",
    "df_b = df_a.assign(\n",
    "    fronted = lambda d: d[\"V1\"].apply(lambda y: 1 if y in [\"ø\", \"e\", \"y\", \"i\"] else 0)\n",
    ")\n",
    "df_c = df_b.assign(\n",
    "    high = lambda d: d[\"V1\"].apply(lambda y: 1 if y in[\"ø\", \"u\", \"y\", \"o\", \"i\", \"ɯ\"] else 0)\n",
    ")\n",
    "print(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      V1 V2 consonant underlying fronted rounded high     group model  Time  \\\n",
      "0      i  H         b       ib-H       1       0    1  rounding     1     5   \n",
      "1      a  H         b       ab-H       0       0    0  rounding     1     5   \n",
      "2      e  H         b       eb-H       1       0    0  rounding     1     5   \n",
      "3      o  H         b       ob-H       0       1    1  rounding     1     5   \n",
      "4      u  H         b       ub-H       0       1    1  rounding     1     5   \n",
      "...   .. ..       ...        ...     ...     ...  ...       ...   ...   ...   \n",
      "14395  o  L         d       od-L       0       1    1  fronting    60     9   \n",
      "14396  u  L         d       ud-L       0       1    1  fronting    60     9   \n",
      "14397  y  L         d       yd-L       1       1    1  fronting    60     9   \n",
      "14398  ø  L         d       ød-L       1       1    1  fronting    60     9   \n",
      "14399  ɯ  L         d       ɯd-L       0       0    1  fronting    60     9   \n",
      "\n",
      "       Attention  \n",
      "0       0.484158  \n",
      "1       0.509531  \n",
      "2       0.547717  \n",
      "3       0.288392  \n",
      "4       0.297703  \n",
      "...          ...  \n",
      "14395   0.165336  \n",
      "14396   0.161891  \n",
      "14397   0.038369  \n",
      "14398   0.021505  \n",
      "14399   0.170912  \n",
      "\n",
      "[14400 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df_melt = pd.melt(\n",
    "    frame=df_c,\n",
    "    id_vars=[\n",
    "        \"V1\", \"V2\", \"consonant\", \"underlying\", \"fronted\", \"rounded\", \"high\", \"group\", \"model\"\n",
    "    ],\n",
    "    value_name=\"Attention\",\n",
    "    value_vars=[5, 6, 7, 8, 9],\n",
    "    var_name=\"Time\"\n",
    ")\n",
    "\n",
    "# set the categories as well\n",
    "df_mle = df_melt.astype(\n",
    "    {\n",
    "        \"Time\": 'int64', \n",
    "        \"V1\": 'category', \n",
    "        \"V2\": 'category', \n",
    "        \"consonant\": 'category', \n",
    "        \"fronted\": 'category', \n",
    "        \"rounded\": 'category', \n",
    "        \"high\": 'category', \n",
    "        \"underlying\": 'category',\n",
    "        \"group\": 'category',\n",
    "        \"model\": 'category'\n",
    "    }\n",
    ")\n",
    "print(df_mle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate groups & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = sm.datasets.get_rdataset(\"dietox\", \"geepack\").data\n",
    "# print(data.dtypes)\n",
    "\n",
    "# save the dataframe\n",
    "df_mle.to_csv('model_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Attention</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th>V2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fronting</th>\n",
       "      <th>H</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.123066</td>\n",
       "      <td>0.143504</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.078244</td>\n",
       "      <td>0.160451</td>\n",
       "      <td>1.244949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.135016</td>\n",
       "      <td>0.144760</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.179309</td>\n",
       "      <td>1.279259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">round_and_front</th>\n",
       "      <th>H</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.367989</td>\n",
       "      <td>0.350564</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.050117</td>\n",
       "      <td>0.253214</td>\n",
       "      <td>0.654266</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.339823</td>\n",
       "      <td>0.350569</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>0.194170</td>\n",
       "      <td>0.620681</td>\n",
       "      <td>1.515658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rounding</th>\n",
       "      <th>H</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.417634</td>\n",
       "      <td>0.271103</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.165114</td>\n",
       "      <td>0.428148</td>\n",
       "      <td>0.617737</td>\n",
       "      <td>1.236852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.331111</td>\n",
       "      <td>0.297902</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>0.235404</td>\n",
       "      <td>0.563806</td>\n",
       "      <td>1.247287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Attention                                          \\\n",
       "                       count      mean       std       min       25%   \n",
       "group           V2                                                     \n",
       "fronting        H     2400.0  0.123066  0.143504  0.000032  0.030641   \n",
       "                L     2400.0  0.135016  0.144760  0.000025  0.038377   \n",
       "round_and_front H     2400.0  0.367989  0.350564  0.000007  0.050117   \n",
       "                L     2400.0  0.339823  0.350569  0.000010  0.033970   \n",
       "rounding        H     2400.0  0.417634  0.271103  0.000390  0.165114   \n",
       "                L     2400.0  0.331111  0.297902  0.000014  0.064440   \n",
       "\n",
       "                                                  \n",
       "                         50%       75%       max  \n",
       "group           V2                                \n",
       "fronting        H   0.078244  0.160451  1.244949  \n",
       "                L   0.096677  0.179309  1.279259  \n",
       "round_and_front H   0.253214  0.654266  1.510183  \n",
       "                L   0.194170  0.620681  1.515658  \n",
       "rounding        H   0.428148  0.617737  1.236852  \n",
       "                L   0.235404  0.563806  1.247287  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean attention for each group for each V2\n",
    "df_mle.groupby([\"group\", \"V2\"])[[\"Attention\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed linear effect models for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounding results:\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: Attention\n",
      "No. Observations:  4800    Method:             ML       \n",
      "No. Groups:        20      Scale:              0.0660   \n",
      "Min. group size:   240     Log-Likelihood:     -318.2120\n",
      "Max. group size:   240     Converged:          Yes      \n",
      "Mean group size:   240.0                                \n",
      "--------------------------------------------------------\n",
      "             Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept    -0.104    0.027  -3.845 0.000 -0.158 -0.051\n",
      "V2[T.L]      -0.087    0.007 -11.669 0.000 -0.101 -0.072\n",
      "fronted[T.1]  0.045    0.007   6.004 0.000  0.030  0.059\n",
      "rounded[T.1]  0.072    0.009   7.942 0.000  0.054  0.090\n",
      "high[T.1]     0.020    0.010   1.949 0.051 -0.000  0.041\n",
      "Time          0.064    0.003  24.437 0.000  0.059  0.069\n",
      "Group Var     0.006    0.012                            \n",
      "========================================================\n",
      "\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "     H      L  -0.0865   0.0 -0.1026 -0.0704   True\n",
      "---------------------------------------------------\n",
      "fronting results:\n",
      "         Mixed Linear Model Regression Results\n",
      "=======================================================\n",
      "Model:            MixedLM Dependent Variable: Attention\n",
      "No. Observations: 4800    Method:             ML       \n",
      "No. Groups:       20      Scale:              0.0164   \n",
      "Min. group size:  240     Log-Likelihood:     3016.2794\n",
      "Max. group size:  240     Converged:          Yes      \n",
      "Mean group size:  240.0                                \n",
      "-------------------------------------------------------\n",
      "             Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------\n",
      "Intercept     0.059    0.017  3.475 0.001  0.026  0.093\n",
      "V2[T.L]       0.012    0.004  3.234 0.001  0.005  0.019\n",
      "fronted[T.1]  0.035    0.004  9.588 0.000  0.028  0.043\n",
      "rounded[T.1]  0.000    0.005  0.049 0.961 -0.009  0.009\n",
      "high[T.1]    -0.030    0.005 -5.658 0.000 -0.040 -0.019\n",
      "Time          0.010    0.001  7.463 0.000  0.007  0.012\n",
      "Group Var     0.004    0.009                           \n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     H      L   0.0119 0.0041 0.0038 0.0201   True\n",
      "--------------------------------------------------\n",
      "round_and_front results:\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: Attention\n",
      "No. Observations:  4800    Method:             ML       \n",
      "No. Groups:        20      Scale:              0.0560   \n",
      "Min. group size:   240     Log-Likelihood:     73.3934  \n",
      "Max. group size:   240     Converged:          Yes      \n",
      "Mean group size:   240.0                                \n",
      "--------------------------------------------------------\n",
      "             Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept    -0.842    0.027 -30.856 0.000 -0.895 -0.788\n",
      "V2[T.L]      -0.028    0.007  -4.125 0.000 -0.042 -0.015\n",
      "fronted[T.1]  0.046    0.007   6.776 0.000  0.033  0.060\n",
      "rounded[T.1] -0.014    0.008  -1.656 0.098 -0.030  0.003\n",
      "high[T.1]    -0.005    0.010  -0.488 0.626 -0.024  0.014\n",
      "Time          0.171    0.002  70.844 0.000  0.166  0.176\n",
      "Group Var     0.008    0.011                            \n",
      "========================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "     H      L  -0.0282 0.0054 -0.048 -0.0083   True\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "''' From paper:\n",
    "We used the identity of input V2 as \n",
    "    - either a high harmony trigger (/i, u/) \n",
    "      or a non-high non-trigger\n",
    "    - and decoder timepoint as main factors, \n",
    "    - model as a random factor, \n",
    "    - and the attention value assigned to the encoder hidden state \n",
    "        associated with input V2 as the dependent variable.\n",
    "\n",
    "This result suggests that the\n",
    "decoder learns to pay more attention to a V2 at an\n",
    "earlier timepoint when that V2 is a harmony trigger,\n",
    "consistent with the representation of an anticipatory\n",
    "(early-activating) gesture assumed by the Gestural\n",
    "Harmony Model.\n",
    "'''\n",
    "\n",
    "# first fit a mixed linear model for each group\n",
    "\n",
    "# divide the df into groups\n",
    "rounding_df = df_mle[df_mle['group'] == 'rounding']\n",
    "fronting_df = df_mle[df_mle['group'] == 'fronting']\n",
    "two_way_df = df_mle[df_mle['group'] == 'round_and_front']\n",
    "grouped_dfs = [rounding_df, fronting_df, two_way_df]\n",
    "\n",
    "# perform an MLE on each group\n",
    "linear_models = []\n",
    "for grp in grouped_dfs:\n",
    "  # model training (see: https://stats.stackexchange.com/questions/415041/am-i-using-the-right-linear-mixed-model-design-for-my-data)\n",
    "  md = smf.mixedlm(\"Attention ~ Time + V2 + fronted + rounded + high\", grp, groups=grp[\"model\"])\n",
    "  mdf = md.fit(reml=False)\n",
    "  linear_models.append(mdf)\n",
    "  print(f\"{grp['group'].values[0]} results:\")\n",
    "  print(mdf.summary())\n",
    "\n",
    "  # # tukey HSD\n",
    "  mc = MultiComparison(grp['Attention'], groups=grp['V2'])\n",
    "  print(mc.tukeyhsd().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounding BIC: 704.2350027424596\n",
      "fronting BIC: -5964.747841267892\n",
      "round_and_front BIC: -78.97573248954939\n"
     ]
    }
   ],
   "source": [
    "# compare model BIC\n",
    "for m, grp in zip(linear_models, grouped_dfs):\n",
    "    print(f\"{grp['group'].values[0]} BIC: {m.bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare attention across groups (one model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hillel/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        Attention\n",
      "No. Observations:        14400          Method:                    REML     \n",
      "No. Groups:              60             Scale:                     0.0563   \n",
      "Min. group size:         240            Log-Likelihood:            165.3222 \n",
      "Max. group size:         240            Converged:                 Yes      \n",
      "Mean group size:         240.0                                              \n",
      "----------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                        -0.448    0.020 -22.416 0.000 -0.487 -0.409\n",
      "group[T.round_and_front]          0.245    0.025   9.931 0.000  0.197  0.293\n",
      "group[T.rounding]                 0.295    0.025  11.944 0.000  0.246  0.343\n",
      "V2[T.L]                           0.012    0.007   1.745 0.081 -0.001  0.025\n",
      "group[T.round_and_front]:V2[T.L] -0.040    0.010  -4.142 0.000 -0.059 -0.021\n",
      "group[T.rounding]:V2[T.L]        -0.098    0.010 -10.168 0.000 -0.117 -0.079\n",
      "Time                              0.082    0.001  58.387 0.000  0.079  0.084\n",
      "Group Var                         0.006    0.005                            \n",
      "============================================================================\n",
      "\n",
      "        Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "====================================================================\n",
      "     group1          group2     meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------------------------\n",
      "       fronting round_and_front   0.2249   -0.0 0.2117  0.238   True\n",
      "       fronting        rounding   0.2453   -0.0 0.2322 0.2585   True\n",
      "round_and_front        rounding   0.0205 0.0008 0.0073 0.0336   True\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# one mixed linear effects model\n",
    "md = smf.mixedlm(\"Attention ~ Time + group * V2\", df_mle, groups=df_mle[\"model\"])\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "## tukey HSD\n",
    "mc = MultiComparison(df_mle['Attention'], groups=df_mle['group'])\n",
    "print(mc.tukeyhsd().summary())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e86c00212425bd2fc84232e5edf67c3bf816ef44de5709770dab76c6c537ba08"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
